<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced features · DifferentiationInterface.jl</title><meta name="title" content="Advanced features · DifferentiationInterface.jl"/><meta property="og:title" content="Advanced features · DifferentiationInterface.jl"/><meta property="twitter:title" content="Advanced features · DifferentiationInterface.jl"/><meta name="description" content="Documentation for DifferentiationInterface.jl."/><meta property="og:description" content="Documentation for DifferentiationInterface.jl."/><meta property="twitter:description" content="Documentation for DifferentiationInterface.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="DifferentiationInterface.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">DifferentiationInterface.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/basic/">Basic tutorial</a></li><li><a class="tocitem" href="../../tutorials/advanced/">Advanced tutorial</a></li></ul></li><li><span class="tocitem">Explanation</span><ul><li><a class="tocitem" href="../operators/">Operators</a></li><li><a class="tocitem" href="../backends/">Backends</a></li><li class="is-active"><a class="tocitem" href>Advanced features</a><ul class="internal"><li><a class="tocitem" href="#Contexts"><span>Contexts</span></a></li><li><a class="tocitem" href="#Sparsity"><span>Sparsity</span></a></li><li><a class="tocitem" href="#Batch-mode"><span>Batch mode</span></a></li></ul></li></ul></li><li><span class="tocitem">FAQ</span><ul><li><a class="tocitem" href="../../faq/limitations/">Limitations</a></li><li><a class="tocitem" href="../../faq/differentiability/">Differentiability</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li><li><a class="tocitem" href="../../dev_guide/">Dev guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Explanation</a></li><li class="is-active"><a href>Advanced features</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced features</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaDiff/DifferentiationInterface.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaDiff/DifferentiationInterface.jl/blob/main/DifferentiationInterface/docs/src/explanation/advanced.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Advanced-features"><a class="docs-heading-anchor" href="#Advanced-features">Advanced features</a><a id="Advanced-features-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-features" title="Permalink"></a></h1><h2 id="Contexts"><a class="docs-heading-anchor" href="#Contexts">Contexts</a><a id="Contexts-1"></a><a class="docs-heading-anchor-permalink" href="#Contexts" title="Permalink"></a></h2><h3 id="Additional-arguments"><a class="docs-heading-anchor" href="#Additional-arguments">Additional arguments</a><a id="Additional-arguments-1"></a><a class="docs-heading-anchor-permalink" href="#Additional-arguments" title="Permalink"></a></h3><p>For all operators provided DifferentiationInterface, there can be only one differentiated (or &quot;active&quot;) argument, which we call <code>x</code>. However, the release v0.6 introduced the possibility of additional &quot;context&quot; arguments, which are not differentiated but still passed to the function after <code>x</code>.</p><p>Contexts can be useful if you have a function <code>y = f(x, a, b, c, ...)</code> or <code>f!(y, x, a, b, c, ...)</code> and you want derivatives of <code>y</code> with respect to <code>x</code> only. Another option would be creating a closure, but that is sometimes undesirable.</p><h3 id="Types-of-contexts"><a class="docs-heading-anchor" href="#Types-of-contexts">Types of contexts</a><a id="Types-of-contexts-1"></a><a class="docs-heading-anchor-permalink" href="#Types-of-contexts" title="Permalink"></a></h3><p>Every context argument must be wrapped in a subtype of <a href="../../api/#DifferentiationInterface.Context"><code>Context</code></a> and come after the differentiated input <code>x</code>. Right now, there are two kinds of context: <a href="../../api/#DifferentiationInterface.Constant"><code>Constant</code></a> and <a href="../../api/#DifferentiationInterface.Cache"><code>Cache</code></a>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Not every backend supports every type of context. See the documentation on <a href="../backends/#Backends">Backends</a> for more details.</p></div></div><p>Semantically, both of these calls compute the partial gradient of <code>f(x, c)</code> with respect to <code>x</code>, but they consider <code>c</code> differently:</p><pre><code class="language-julia hljs">gradient(f, backend, x, Constant(c))
gradient(f, backend, x, Cache(c))</code></pre><p>In the first call, <code>c</code> is kept unchanged throughout the function evaluation. In the second call, <code>c</code> can be mutated with values computed during the function.</p><p>Importantly, one can prepare an operator with an arbitrary value <code>c&#39;</code> of the <code>Constant</code> (subject to the usual restrictions on preparation). The values in a provided <code>Cache</code> never matter anyway.</p><h2 id="Sparsity"><a class="docs-heading-anchor" href="#Sparsity">Sparsity</a><a id="Sparsity-1"></a><a class="docs-heading-anchor-permalink" href="#Sparsity" title="Permalink"></a></h2><p>When faced with sparse Jacobian or Hessian matrices, one can take advantage of their sparsity pattern to speed up the computation. DifferentiationInterface does this automatically if you pass a backend of type <a href="https://sciml.github.io/ADTypes.jl/stable/#ADTypes.AutoSparse"><code>AutoSparse</code></a>.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>To know more about sparse AD, read the survey <a href="https://epubs.siam.org/doi/10.1137/S0036144504444711"><em>What Color Is Your Jacobian? Graph Coloring for Computing Derivatives</em></a> (Gebremedhin et al., 2005).</p></div></div><h3 id="AutoSparse-object"><a class="docs-heading-anchor" href="#AutoSparse-object"><code>AutoSparse</code> object</a><a id="AutoSparse-object-1"></a><a class="docs-heading-anchor-permalink" href="#AutoSparse-object" title="Permalink"></a></h3><p><code>AutoSparse</code> backends only support <a href="../../api/#DifferentiationInterface.jacobian"><code>jacobian</code></a> and <a href="../../api/#DifferentiationInterface.hessian"><code>hessian</code></a> (as well as their variants), because other operators do not output matrices. An <code>AutoSparse</code> backend must be constructed from three ingredients:</p><ol><li>An underlying (dense) backend, which can be <a href="../../api/#DifferentiationInterface.SecondOrder"><code>SecondOrder</code></a> or anything from <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a></li><li>A sparsity pattern detector like:<ul><li><a href="https://adrianhill.de/SparseConnectivityTracer.jl/stable/user/api/#SparseConnectivityTracer.TracerSparsityDetector"><code>TracerSparsityDetector</code></a> from <a href="https://github.com/adrhill/SparseConnectivityTracer.jl">SparseConnectivityTracer.jl</a></li><li><a href="https://symbolics.juliasymbolics.org/stable/manual/sparsity_detection/#Symbolics.SymbolicsSparsityDetector"><code>SymbolicsSparsityDetector</code></a> from <a href="https://github.com/JuliaSymbolics/Symbolics.jl">Symbolics.jl</a></li><li><a href="../../api/#DifferentiationInterface.DenseSparsityDetector"><code>DenseSparsityDetector</code></a> from DifferentiationInterface.jl (beware that this detector only gives a locally valid pattern)</li><li><a href="https://sciml.github.io/ADTypes.jl/stable/#ADTypes.KnownJacobianSparsityDetector"><code>KnownJacobianSparsityDetector</code></a> or <a href="https://sciml.github.io/ADTypes.jl/stable/#ADTypes.KnownHessianSparsityDetector"><code>KnownHessianSparsityDetector</code></a> from <a href="https://github.com/SciML/ADTypes.jl">ADTypes.jl</a> (if you already know the pattern)</li></ul></li><li>A coloring algorithm from <a href="https://github.com/gdalle/SparseMatrixColorings.jl">SparseMatrixColorings.jl</a>, such as:<ul><li><a href="https://gdalle.github.io/SparseMatrixColorings.jl/stable/api/#SparseMatrixColorings.GreedyColoringAlgorithm"><code>GreedyColoringAlgorithm</code></a> (our generic recommendation)</li><li><a href="https://gdalle.github.io/SparseMatrixColorings.jl/stable/api/#SparseMatrixColorings.ConstantColoringAlgorithm"><code>ConstantColoringAlgorithm</code></a> (if you have already computed the optimal coloring and always want to return it)</li></ul></li></ol><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Symbolic backends have built-in sparsity handling, so <code>AutoSparse(AutoSymbolics())</code> and <code>AutoSparse(AutoFastDifferentiation())</code> do not need additional configuration for pattern detection or coloring.</p></div></div><h3 id="Cost-of-sparse-preparation"><a class="docs-heading-anchor" href="#Cost-of-sparse-preparation">Cost of sparse preparation</a><a id="Cost-of-sparse-preparation-1"></a><a class="docs-heading-anchor-permalink" href="#Cost-of-sparse-preparation" title="Permalink"></a></h3><p>The preparation step of <code>jacobian</code> or <code>hessian</code> with an <code>AutoSparse</code> backend can be long, because it needs to detect the sparsity pattern and perform a matrix coloring. But after preparation, the more zeros are present in the matrix, the greater the speedup will be compared to dense differentiation.</p><div class="admonition is-danger"><header class="admonition-header">Danger</header><div class="admonition-body"><p>The result of preparation for an <code>AutoSparse</code> backend cannot be reused if the sparsity pattern changes.</p></div></div><h3 id="Tuning-the-coloring-algorithm"><a class="docs-heading-anchor" href="#Tuning-the-coloring-algorithm">Tuning the coloring algorithm</a><a id="Tuning-the-coloring-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Tuning-the-coloring-algorithm" title="Permalink"></a></h3><p>The complexity of sparse Jacobians or Hessians grows with the number of distinct colors in a coloring of the sparsity pattern. To reduce this number of colors, <a href="https://gdalle.github.io/SparseMatrixColorings.jl/stable/api/#SparseMatrixColorings.GreedyColoringAlgorithm"><code>GreedyColoringAlgorithm</code></a> has two main settings: the order used for vertices and the decompression method. Depending on your use case, you may want to modify either of these options to increase performance. See the documentation of <a href="https://github.com/gdalle/SparseMatrixColorings.jl">SparseMatrixColorings.jl</a> for details.</p><h3 id="Mixed-mode"><a class="docs-heading-anchor" href="#Mixed-mode">Mixed mode</a><a id="Mixed-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Mixed-mode" title="Permalink"></a></h3><p>When a Jacobian matrix has both dense rows and dense columns, it can be more efficient to use &quot;mixed-mode&quot; differentiation, a mixture of forward and reverse. The associated bidirectional coloring algorithm automatically decides how to cover the Jacobian using a set of columns (computed in forward mode) plus a set of rows (computed in reverse mode). This behavior is triggered as soon as you put a <a href="../../api/#DifferentiationInterface.MixedMode"><code>MixedMode</code></a> object inside <code>AutoSparse</code>, like so:</p><pre><code class="language-julia hljs">AutoSparse(
    MixedMode(forward_backend, reverse_backend);
    sparsity_detector,
    coloring_algorithm
)</code></pre><p>At the moment, mixed mode tends to work best when the <a href="https://gdalle.github.io/SparseMatrixColorings.jl/stable/api/#SparseMatrixColorings.GreedyColoringAlgorithm"><code>GreedyColoringAlgorithm</code></a> is provided with a <a href="https://gdalle.github.io/SparseMatrixColorings.jl/stable/api/#SparseMatrixColorings.RandomOrder"><code>RandomOrder</code></a> instead of the usual <a href="https://gdalle.github.io/SparseMatrixColorings.jl/stable/api/#SparseMatrixColorings.NaturalOrder"><code>NaturalOrder</code></a>.</p><h2 id="Batch-mode"><a class="docs-heading-anchor" href="#Batch-mode">Batch mode</a><a id="Batch-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-mode" title="Permalink"></a></h2><h3 id="Multiple-tangents"><a class="docs-heading-anchor" href="#Multiple-tangents">Multiple tangents</a><a id="Multiple-tangents-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-tangents" title="Permalink"></a></h3><p>The <a href="../../api/#DifferentiationInterface.jacobian"><code>jacobian</code></a> and <a href="../../api/#DifferentiationInterface.hessian"><code>hessian</code></a> operators compute matrices by repeatedly applying lower-level operators (<a href="../../api/#DifferentiationInterface.pushforward"><code>pushforward</code></a>, <a href="../../api/#DifferentiationInterface.pullback"><code>pullback</code></a> or <a href="../../api/#DifferentiationInterface.hvp"><code>hvp</code></a>) to a set of tangents. The tangents usually correspond to basis elements of the appropriate vector space. We could call the lower-level operator on each tangent separately, but some packages (<a href="https://github.com/JuliaDiff/ForwardDiff.jl">ForwardDiff.jl</a> and <a href="https://github.com/EnzymeAD/Enzyme.jl">Enzyme.jl</a>) have optimized implementations to handle multiple tangents at once.</p><p>This behavior is often called &quot;vector mode&quot; AD, but we call it &quot;batch mode&quot; to avoid confusion with Julia&#39;s <code>Vector</code> type. As a matter of fact, the optimal batch size <span>$B$</span> (number of simultaneous tangents) is usually very small, so tangents are passed within an <code>NTuple</code> and not a <code>Vector</code>. When the underlying vector space has dimension <span>$N$</span>, the operators <code>jacobian</code> and <code>hessian</code> process <span>$\lceil N / B \rceil$</span> batches of size <span>$B$</span> each.</p><h3 id="Optimal-batch-size"><a class="docs-heading-anchor" href="#Optimal-batch-size">Optimal batch size</a><a id="Optimal-batch-size-1"></a><a class="docs-heading-anchor-permalink" href="#Optimal-batch-size" title="Permalink"></a></h3><p>For every backend which does not support batch mode, the batch size is set to <span>$B = 1$</span>. But for <a href="https://sciml.github.io/ADTypes.jl/stable/#ADTypes.AutoForwardDiff"><code>AutoForwardDiff</code></a> and <a href="https://sciml.github.io/ADTypes.jl/stable/#ADTypes.AutoEnzyme"><code>AutoEnzyme</code></a>, more complicated rules apply. If the backend object has a pre-determined batch size <span>$B_0$</span>, then we always set <span>$B = B_0$</span>. In particular, this will throw errors when <span>$N &lt; B_0$</span>. On the other hand, without a pre-determined batch size, we apply backend-specific heuristics to pick <span>$B$</span> based on <span>$N$</span>.</p><script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: true,
    theme: "neutral"
});
</script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../backends/">« Backends</a><a class="docs-footer-nextpage" href="../../faq/limitations/">Limitations »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.10.0 on <span class="colophon-date" title="Monday 31 March 2025 13:33">Monday 31 March 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
